import torch
import torch.nn as nn
import netron
import os
import argparse
import numpy as np

# ä»è®­ç»ƒè„šæœ¬å¤åˆ¶ALSTMæ¨¡å‹å®šä¹‰ï¼ˆç¡®ä¿ä¸è½¬æ¢è„šæœ¬ä¸€è‡´ï¼‰
class ALSTMModel(nn.Module):
    """
    ALSTMæ¨¡å‹çš„æ ¸å¿ƒç»“æ„ã€‚
    """

    def __init__(self, d_feat=6, hidden_size=64, num_layers=2, dropout=0.0, n_instruments=0, embedding_dim=4,
                 n_classes=3):
        super().__init__()
        self.d_feat = d_feat
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.dropout = dropout
        self.n_instruments = n_instruments
        self.embedding_dim = embedding_dim
        self.n_classes = n_classes

        self.instrument_embedding = nn.Embedding(num_embeddings=self.n_instruments, embedding_dim=self.embedding_dim)
        self.fc_in = nn.Linear(in_features=self.d_feat + self.embedding_dim, out_features=self.hidden_size)
        self.act = nn.Tanh()
        self.rnn = nn.LSTM(
            input_size=self.hidden_size,
            hidden_size=self.hidden_size,
            num_layers=self.num_layers,
            batch_first=True,
            dropout=self.dropout,
        )
        self.att_net = nn.Sequential(
            nn.Linear(in_features=self.hidden_size, out_features=int(self.hidden_size / 2)),
            nn.Dropout(self.dropout),
            nn.Tanh(),
            nn.Linear(in_features=int(self.hidden_size / 2), out_features=1, bias=False),
            nn.Softmax(dim=1)
        )
        self.fc_out = nn.Linear(in_features=self.hidden_size * 2, out_features=self.n_classes)

    def forward(self, x_continuous, x_instrument):
        instrument_embed = self.instrument_embedding(x_instrument)
        x = torch.cat([x_continuous, instrument_embed], dim=2)
        x = self.act(self.fc_in(x))
        rnn_out, _ = self.rnn(x)
        attention_score = self.att_net(rnn_out)
        out_att = torch.mul(rnn_out, attention_score)
        out_att = torch.sum(out_att, dim=1)
        out = self.fc_out(torch.cat((rnn_out[:, -1, :], out_att), dim=1))
        return out

def visualize_alstm_model(args):
    """
    åŠ è½½ALSTMæ¨¡å‹å¹¶ç”Ÿæˆå¯è§†åŒ–ç»“æ„å›¾
    """
    print(f"--- å¼€å§‹ALSTMæ¨¡å‹å¯è§†åŒ– ---")
    print(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(args.model_path):
            print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")
            print("è¯·å…ˆè¿è¡Œ alstm_pkl_to_pt.py æ¥ç”Ÿæˆ.ptæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶")
            return False
        
        # åŠ è½½æ¨¡å‹
        model = torch.load(args.model_path, map_location='cpu')
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        print("âœ… æˆåŠŸåŠ è½½ALSTMæ¨¡å‹")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print(f"\n--- æ¨¡å‹ä¿¡æ¯ ---")
        print(f"æ¨¡å‹ç±»å‹: {type(model)}")
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters() if p.requires_grad)}")
        
        # åˆ›å»ºdummyè¾“å…¥
        # ALSTMæ¨¡å‹éœ€è¦ä¸¤ä¸ªè¾“å…¥ï¼šè¿ç»­ç‰¹å¾å’Œå“ç§ç´¢å¼•
        batch_size = 1
        seq_len = 10  # æ—¶é—´æ­¥é•¿
        d_feat = model.d_feat
        n_instruments = model.n_instruments
        
        print(f"\n--- åˆ›å»ºDummyè¾“å…¥ ---")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"åºåˆ—é•¿åº¦: {seq_len}")
        print(f"ç‰¹å¾ç»´åº¦: {d_feat}")
        print(f"å“ç§æ•°é‡: {n_instruments}")
        
        # åˆ›å»ºdummyè¾“å…¥
        dummy_x_continuous = torch.randn(batch_size, seq_len, d_feat)
        dummy_x_instrument = torch.randint(0, n_instruments, (batch_size, seq_len))
        
        print(f"è¿ç»­ç‰¹å¾è¾“å…¥å½¢çŠ¶: {dummy_x_continuous.shape}")
        print(f"å“ç§ç´¢å¼•è¾“å…¥å½¢çŠ¶: {dummy_x_instrument.shape}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = model(dummy_x_continuous, dummy_x_instrument)
            print(f"æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # å¯¼å‡ºä¸ºONNXæ ¼å¼
        onnx_path = os.path.join(os.path.dirname(args.model_path), 'alstm_model.onnx')
        
        print(f"\n--- å¯¼å‡ºONNXæ¨¡å‹ ---")
        print(f"ONNXæ–‡ä»¶è·¯å¾„: {onnx_path}")
        
        torch.onnx.export(
            model,
            (dummy_x_continuous, dummy_x_instrument),  # æ¨¡å‹è¾“å…¥
            onnx_path,
            input_names=["x_continuous", "x_instrument"],
            output_names=["output"],
            dynamic_axes={
                "x_continuous": {0: "batch_size", 1: "seq_len"},
                "x_instrument": {0: "batch_size", 1: "seq_len"},
                "output": {0: "batch_size"}
            },
            opset_version=11,
            verbose=True
        )
        
        print(f"âœ… æˆåŠŸå¯¼å‡ºONNXæ¨¡å‹: {onnx_path}")
        
        # ä½¿ç”¨Netronå¯è§†åŒ–
        print(f"\n--- å¯åŠ¨Netronå¯è§†åŒ– ---")
        print("æ­£åœ¨æ‰“å¼€æµè§ˆå™¨æ˜¾ç¤ºæ¨¡å‹ç»“æ„å›¾...")
        print("å¦‚æœæµè§ˆå™¨æ²¡æœ‰è‡ªåŠ¨æ‰“å¼€ï¼Œè¯·æ‰‹åŠ¨è®¿é—®æ˜¾ç¤ºçš„URL")
        
        try:
            # å°è¯•å¯åŠ¨netronï¼Œä¸æŒ‡å®športå‚æ•°
            netron.start(onnx_path)
            print(f"\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
            print(f"ONNXæ¨¡å‹æ–‡ä»¶: {onnx_path}")
            print("æ¨¡å‹ç»“æ„å›¾å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
        except Exception as e:
            print(f"âš ï¸ Netronå¯åŠ¨å¤±è´¥: {e}")
            print("å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•...")
            try:
                # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥å¯åŠ¨ï¼Œè®©netronè‡ªåŠ¨é€‰æ‹©ç«¯å£
                netron.start(onnx_path, browse=True)
                print(f"\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
                print(f"ONNXæ¨¡å‹æ–‡ä»¶: {onnx_path}")
                print("æ¨¡å‹ç»“æ„å›¾å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€")
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                print(f"è¯·æ‰‹åŠ¨æ‰“å¼€æµè§ˆå™¨è®¿é—®: file://{os.path.abspath(onnx_path)}")
                print("æˆ–è€…å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„netron: pip install --upgrade netron")
        
        return True
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    parser = argparse.ArgumentParser(description="ALSTMæ¨¡å‹å¯è§†åŒ–å·¥å…·")
    
    parser.add_argument('--model_path', type=str,
                        default=os.path.join(base_dir, '../experiments/models/ALSTM_tuned_classification/alstm_model.pt'),
                        help='ALSTMæ¨¡å‹æ–‡ä»¶è·¯å¾„(.ptæ ¼å¼)')
    
    args = parser.parse_args()
    
    success = visualize_alstm_model(args)
    
    if success:
        print(f"\nâœ… å¯è§†åŒ–æµç¨‹å®Œæˆï¼")
        print("è¯·åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹æ¨¡å‹ç»“æ„å›¾")
    else:
        print(f"\nâŒ å¯è§†åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        print("ç¡®ä¿å·²è¿è¡Œ alstm_pkl_to_pt.py ç”Ÿæˆ.ptæ ¼å¼çš„æ¨¡å‹æ–‡ä»¶") 
