import argparse
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import pickle
import os
import json
from torch.utils.data import DataLoader, Dataset

# ä»è®­ç»ƒè„šæœ¬å¤åˆ¶ALSTMæ¨¡å‹å®šä¹‰
class ALSTMModel(nn.Module):
    """
    ALSTMæ¨¡å‹çš„æ ¸å¿ƒç»“æ„ã€‚
    """

    def __init__(self, d_feat=6, hidden_size=64, num_layers=2, dropout=0.0, n_instruments=0, embedding_dim=4,
                 n_classes=3):
        super().__init__()
        self.d_feat = d_feat
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.dropout = dropout
        self.n_instruments = n_instruments
        self.embedding_dim = embedding_dim
        self.n_classes = n_classes

        self.instrument_embedding = nn.Embedding(num_embeddings=self.n_instruments, embedding_dim=self.embedding_dim)
        self.fc_in = nn.Linear(in_features=self.d_feat + self.embedding_dim, out_features=self.hidden_size)
        self.act = nn.Tanh()
        self.rnn = nn.LSTM(
            input_size=self.hidden_size,
            hidden_size=self.hidden_size,
            num_layers=self.num_layers,
            batch_first=True,
            dropout=self.dropout,
        )
        self.att_net = nn.Sequential(
            nn.Linear(in_features=self.hidden_size, out_features=int(self.hidden_size / 2)),
            nn.Dropout(self.dropout),
            nn.Tanh(),
            nn.Linear(in_features=int(self.hidden_size / 2), out_features=1, bias=False),
            nn.Softmax(dim=1)
        )
        self.fc_out = nn.Linear(in_features=self.hidden_size * 2, out_features=self.n_classes)

    def forward(self, x_continuous, x_instrument):
        instrument_embed = self.instrument_embedding(x_instrument)
        x = torch.cat([x_continuous, instrument_embed], dim=2)
        x = self.act(self.fc_in(x))
        rnn_out, _ = self.rnn(x)
        attention_score = self.att_net(rnn_out)
        out_att = torch.mul(rnn_out, attention_score)
        out_att = torch.sum(out_att, dim=1)
        out = self.fc_out(torch.cat((rnn_out[:, -1, :], out_att), dim=1))
        return out

def load_and_convert_model(args):
    """
    åŠ è½½.pklæ¨¡å‹å¹¶è½¬æ¢ä¸º.ptæ ¼å¼
    """
    print(f"--- å¼€å§‹åŠ è½½æ¨¡å‹å¹¶è½¬æ¢æ ¼å¼ ---")
    print(f"æ¨¡å‹ç›®å½•: {args.model_dir}")
    
    try:
        # åŠ è½½æœ€ä¼˜å‚æ•°
        with open(os.path.join(args.model_dir, 'best_params_results.json'), 'r') as f:
            best_params = json.load(f)
        print("âœ… æˆåŠŸåŠ è½½æœ€ä¼˜è¶…å‚æ•°")
        
        # åŠ è½½instrumentæ˜ å°„
        try:
            with open(os.path.join(args.model_dir, 'instrument_map.pkl'), 'rb') as f:
                instrument_map = pickle.load(f)
            print("âœ… æˆåŠŸåŠ è½½å“ç§æ˜ å°„è¡¨")
        except ModuleNotFoundError as e:
            if "numpy._core" in str(e):
                print("âš ï¸ æ£€æµ‹åˆ°numpyç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œå°è¯•ä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½...")
                # å°è¯•ä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½
                import pickle5 as pickle_compat
                try:
                    with open(os.path.join(args.model_dir, 'instrument_map.pkl'), 'rb') as f:
                        instrument_map = pickle_compat.load(f)
                    print("âœ… ä½¿ç”¨å…¼å®¹æ¨¡å¼æˆåŠŸåŠ è½½å“ç§æ˜ å°„è¡¨")
                except ImportError:
                    print("âŒ æ— æ³•å¯¼å…¥pickle5ï¼Œå°è¯•å…¶ä»–è§£å†³æ–¹æ¡ˆ...")
                    # å¦‚æœpickle5ä¸å¯ç”¨ï¼Œå°è¯•é‡æ–°åˆ›å»ºæ˜ å°„
                    print("æ­£åœ¨é‡æ–°åˆ›å»ºå“ç§æ˜ å°„...")
                    full_data = pd.read_parquet(args.data_path)
                    train_data = full_data[full_data['datetime'] < '2024-12-01'].copy()
                    instrument_map = pd.Index(train_data['instrument'].unique())
                    print(f"âœ… é‡æ–°åˆ›å»ºå“ç§æ˜ å°„ï¼ŒåŒ…å« {len(instrument_map)} ä¸ªå“ç§")
            else:
                raise e
        except Exception as e:
            print(f"âŒ åŠ è½½å“ç§æ˜ å°„è¡¨å¤±è´¥: {e}")
            print("å°è¯•é‡æ–°åˆ›å»ºå“ç§æ˜ å°„...")
            full_data = pd.read_parquet(args.data_path)
            train_data = full_data[full_data['datetime'] < '2024-12-01'].copy()
            instrument_map = pd.Index(train_data['instrument'].unique())
            print(f"âœ… é‡æ–°åˆ›å»ºå“ç§æ˜ å°„ï¼ŒåŒ…å« {len(instrument_map)} ä¸ªå“ç§")
        
        # è®¡ç®—d_feat
        full_data = pd.read_parquet(args.data_path)
        feature_cols = [col for col in full_data.columns if not (
                col.startswith('label') or col in ['datetime', 'instrument', 'instrument_idx']
        )]
        d_feat = len(feature_cols)
        print(f"âœ… è®¡ç®—å¾—åˆ°ç‰¹å¾ç»´åº¦ d_feat: {d_feat}")
        
        # æ„å»ºæ¨¡å‹
        n_instruments = len(instrument_map)
        model = ALSTMModel(
            d_feat=d_feat,
            hidden_size=best_params['hidden_size'],
            num_layers=best_params['num_layers'],
            dropout=best_params['dropout'],
            n_instruments=n_instruments,
            embedding_dim=best_params['embedding_dim'],
            n_classes=3
        )
        
        # åŠ è½½.pklæ¨¡å‹æƒé‡
        model_filename = f"alstm_cls_hs{best_params['hidden_size']}_nl{best_params['num_layers']}_do{best_params['dropout']}_ed{best_params['embedding_dim']}_lr{best_params['lr']}_bs{best_params['batch_size']}.pkl"
        model_path = os.path.join(args.model_dir, model_filename)
        
        try:
            checkpoint_state_dict = torch.load(model_path, map_location='cpu')
            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_filename}")
        except ModuleNotFoundError as e:
            if "numpy._core" in str(e):
                print("âš ï¸ æ¨¡å‹æƒé‡åŠ è½½é‡åˆ°numpyç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜...")
                print("å°è¯•ä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½æ¨¡å‹æƒé‡...")
                # å°è¯•ä½¿ç”¨pickle5åŠ è½½
                try:
                    import pickle5 as pickle_compat
                    with open(model_path, 'rb') as f:
                        checkpoint_state_dict = pickle_compat.load(f)
                    print(f"âœ… ä½¿ç”¨å…¼å®¹æ¨¡å¼æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_filename}")
                except ImportError:
                    print("âŒ æ— æ³•ä½¿ç”¨pickle5ï¼Œå°è¯•å…¶ä»–è§£å†³æ–¹æ¡ˆ...")
                    raise e
            else:
                raise e
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹æƒé‡å¤±è´¥: {e}")
            raise e
        
        # åœ¨æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸåæ·»åŠ load_state_dictè°ƒç”¨
        model.load_state_dict(checkpoint_state_dict)
        
        # ä¿å­˜ä¸º.ptæ ¼å¼
        pt_model_path = os.path.join(args.model_dir, 'alstm_model.pt')
        torch.save(model, pt_model_path)
        print(f"âœ… æˆåŠŸä¿å­˜ä¸º.ptæ ¼å¼: {pt_model_path}")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        print(f"\n--- æ¨¡å‹ä¿¡æ¯ ---")
        print(f"ç‰¹å¾ç»´åº¦ (d_feat): {d_feat}")
        print(f"éšè—å±‚å¤§å°: {best_params['hidden_size']}")
        print(f"LSTMå±‚æ•°: {best_params['num_layers']}")
        print(f"Dropoutç‡: {best_params['dropout']}")
        print(f"åµŒå…¥ç»´åº¦: {best_params['embedding_dim']}")
        print(f"å“ç§æ•°é‡: {n_instruments}")
        print(f"è¾“å‡ºç±»åˆ«æ•°: 3")
        
        return pt_model_path, d_feat, best_params
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None

if __name__ == '__main__':
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    parser = argparse.ArgumentParser(description="ALSTMæ¨¡å‹æ ¼å¼è½¬æ¢å·¥å…·")
    
    parser.add_argument('--model_dir', type=str,
                        default=os.path.join(base_dir, 'models/ALSTM_tuned_classification/'),
                        help='åŒ…å«æœ€ä¼˜æ¨¡å‹ã€å‚æ•°å’Œæ˜ å°„è¡¨çš„ç›®å½•è·¯å¾„')
    
    parser.add_argument('--data_path', type=str,
                        default=os.path.join(base_dir, '../data/output/final_data_standardized_with_ud.parquet'),
                        help='é¢„å¤„ç†åçš„æ•°æ®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    pt_model_path, d_feat, best_params = load_and_convert_model(args)
    
    if pt_model_path:
        print(f"\nğŸ‰ è½¬æ¢å®Œæˆï¼æ¨¡å‹å·²ä¿å­˜ä¸º: {pt_model_path}")
        print("ç°åœ¨å¯ä»¥ä½¿ç”¨ alstm_draw_pic.py æ¥å¯è§†åŒ–æ¨¡å‹ç»“æ„äº†ã€‚")
    else:
        print("\nâŒ è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚") 